{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_6_Implementation_of_Softmax_Regression_From_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIwKdIAyu0qeWbonxSr0xW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VirtueZhao/Dive_into_Deep_Learning/blob/main/3_6_Implementation_of_Softmax_Regression_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M30IPVUflMWa"
      },
      "source": [
        "import d2l\n",
        "import torch\n",
        "from IPython import display"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FupdnNJ-mE5J",
        "outputId": "5747ef39-bcc9-473b-d8ac-6b8c29f67ac9"
      },
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G44DxRj3m3MX"
      },
      "source": [
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "\n",
        "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
        "b = torch.zeros(num_outputs, requires_grad=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUMj1PYHohMC",
        "outputId": "4a1f44c4-5947-4427-a785-a6fd54987cf6"
      },
      "source": [
        "X = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(X)\n",
        "print(X.sum(0))\n",
        "print(X.sum(0).shape)\n",
        "print(\"-----\")\n",
        "print(X.sum(0, keepdim=True))\n",
        "print(X.sum(0, keepdim=True).shape)\n",
        "print(\"-----\")\n",
        "print(X.sum(1))\n",
        "print(X.sum(1).shape)\n",
        "print(\"-----\")\n",
        "print(X.sum(1, keepdim=True))\n",
        "print(X.sum(1, keepdim=True).shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([5, 7, 9])\n",
            "torch.Size([3])\n",
            "-----\n",
            "tensor([[5, 7, 9]])\n",
            "torch.Size([1, 3])\n",
            "-----\n",
            "tensor([ 6, 15])\n",
            "torch.Size([2])\n",
            "-----\n",
            "tensor([[ 6],\n",
            "        [15]])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xizjeh9oTau_"
      },
      "source": [
        "def softmax(X):\n",
        "  X_exp = torch.exp(X)\n",
        "  # print(\"X: \", X)\n",
        "  # print(\"X_exp: \", X_exp)\n",
        "  partition = X_exp.sum(1, keepdim=True)\n",
        "  return X_exp / partition"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2fulv_vTz9V",
        "outputId": "a905a091-99a1-49a9-cb16-fdeb58c54bad"
      },
      "source": [
        "X = torch.normal(0,1,(2,5))\n",
        "X_prob = softmax(X)\n",
        "print(\"X_prob: \", X_prob)\n",
        "print(\"X_prob.sum(1): \", X_prob.sum(1,keepdim=True))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  tensor([[-0.9255, -0.5170, -0.8076, -0.6601, -1.7436],\n",
            "        [-0.0203,  0.8960, -0.3690, -0.5898,  1.2350]])\n",
            "X_exp:  tensor([[0.3963, 0.5963, 0.4459, 0.5168, 0.1749],\n",
            "        [0.9799, 2.4499, 0.6914, 0.5545, 3.4382]])\n",
            "X_prob:  tensor([[0.1861, 0.2799, 0.2093, 0.2426, 0.0821],\n",
            "        [0.1208, 0.3019, 0.0852, 0.0683, 0.4237]])\n",
            "X_prob.sum(1):  tensor([[1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54UTZwIdVKdO"
      },
      "source": [
        "def net(X):\n",
        "  return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVKAdyfmVhXp",
        "outputId": "3fe92f68-48df-451b-b594-b3ab6480ee40"
      },
      "source": [
        "y = torch.tensor([0,2])\n",
        "print(\"y: \",y)\n",
        "y_hat = torch.tensor([[0.1,0.3,0.6],[0.3,0.2,0.5]])\n",
        "print(\"y_hat: \",y_hat)\n",
        "print(\"y_hat[[0,1],y]: \",y_hat[[0,1],y])\n",
        "y_hat[[0,1],y] == y_hat[[0,1],[0,2]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y:  tensor([0, 2])\n",
            "y_hat:  tensor([[0.1000, 0.3000, 0.6000],\n",
            "        [0.3000, 0.2000, 0.5000]])\n",
            "y_hat[[0,1],y]:  tensor([0.1000, 0.5000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwlrsdnx32HN",
        "outputId": "a9761edc-1deb-42d3-e4da-e5a333f9c2d4"
      },
      "source": [
        "def cross_entropy(y_hat, y):\n",
        "  # print(\"y_hat: \",y_hat)\n",
        "  # print(\"y: \",y)\n",
        "  # print(\"len(y_hat): \",len(y_hat))\n",
        "  # print(\"range(len(y_hat)): \", range(len(y_hat)))\n",
        "\n",
        "  # print(y_hat[range(len(y_hat)), y])\n",
        "  return -torch.log(y_hat[range(len(y_hat)), y])\n",
        "\n",
        "cross_entropy(y_hat, y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3026, 0.6931])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxpd4psF5yN8",
        "outputId": "93a9ce84-c7d0-46f8-89f8-9932b0849cf7"
      },
      "source": [
        "def accuracy(y_hat, y):\n",
        "  # print(\"y_hat.shape: \", y_hat.shape)\n",
        "  # print(\"y_hat.shape[1]: \", y_hat.shape[1])\n",
        "  # print(\"y_hat: \", y_hat)\n",
        "\n",
        "  if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "    t_hat = y_hat.argmax(axis=0)\n",
        "    # print(\"t_hat: \", t_hat)\n",
        "    y_hat = y_hat.argmax(axis=1)\n",
        "    # print(\"y_hat: \", y_hat)\n",
        "  \n",
        "  # print(\"y type: \",type(y))\n",
        "  # print(\"y_hat type: \",type(y_hat))\n",
        "\n",
        "  cmp = y_hat.type(y.dtype) == y\n",
        "  # print(\"cmp: \",cmp)\n",
        "  # print(\"cmp.type(y.dtype): \",cmp.type(y.dtype))\n",
        "  # print(\"cmp.type(y.dtype).sum(): \",cmp.type(y.dtype).sum())\n",
        "\n",
        "  return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "y_hat = torch.tensor([[0.1,0.3,0.6],[0.3,0.2,0.5]])\n",
        "accuracy(y_hat, y) / len(y)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tt5I7cX5dHM"
      },
      "source": [
        "def evaluate_accuracy(net, data_iter):\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.eval()\n",
        "  metric = Accumulator(2)\n",
        "  for X, y in data_iter:\n",
        "    metric.add(accuracy(net(X), y), y.numel())\n",
        "    # print(\"metric[0]: \", metric[0])\n",
        "    # print(\"metric[1]: \", metric[1])\n",
        "  return metric[0] / metric[1]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il-Iv2ZW6uv2"
      },
      "source": [
        "class Accumulator:\n",
        "  def __init__(self, n):\n",
        "    self.data = [0.0] * n\n",
        "    print(\"self.data: \", self.data)\n",
        "  \n",
        "  def add(self, *args):\n",
        "    print(\"*args\", args)\n",
        "    self.data = [a + float(b) for a,b in zip(self.data, args)]\n",
        "    print(\"zip(self.data, args): \", zip(self.data, args))\n",
        "    # print(\"self.data: \", self.data)\n",
        "\n",
        "  def reset(self):\n",
        "    self.data = [0.0] * len(self.data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIby4lrI-gpB",
        "outputId": "190a1be4-d0a9-4ed4-f1e1-ac11c7cc158b"
      },
      "source": [
        "evaluate_accuracy(net, test_iter)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.data:  [0.0, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*args (45.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a779960>\n",
            "*args (50.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a7f9730>\n",
            "*args (33.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a628fa0>\n",
            "*args (39.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (41.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a62e5f0>\n",
            "*args (41.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a62e5f0>\n",
            "*args (46.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f51e0>\n",
            "*args (41.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6548c0>\n",
            "*args (40.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a76cd20>\n",
            "*args (36.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (35.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a64e4b0>\n",
            "*args (46.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a628fa0>\n",
            "*args (35.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f5e60>\n",
            "*args (44.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a64e8c0>\n",
            "*args (39.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f5e60>\n",
            "*args (41.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6663c0>\n",
            "*args (50.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (36.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (51.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a82b8c0>\n",
            "*args (45.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a666a50>\n",
            "*args (36.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a64e4b0>\n",
            "*args (43.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a628fa0>\n",
            "*args (43.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a628fa0>\n",
            "*args (43.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a8093c0>\n",
            "*args (55.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6008c0>\n",
            "*args (43.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a779960>\n",
            "*args (46.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6008c0>\n",
            "*args (40.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a82b8c0>\n",
            "*args (55.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a62e5f0>\n",
            "*args (40.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6008c0>\n",
            "*args (35.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a628fa0>\n",
            "*args (37.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (39.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a666a50>\n",
            "*args (35.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f5e60>\n",
            "*args (30.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a7c0910>\n",
            "*args (37.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a608370>\n",
            "*args (37.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f9a50>\n",
            "*args (34.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a5f50a0>\n",
            "*args (39.0, 256)\n",
            "zip(self.data, args):  <zip object at 0x7f599a6020a0>\n",
            "*args (2.0, 16)\n",
            "zip(self.data, args):  <zip object at 0x7f599a82b8c0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1603"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}